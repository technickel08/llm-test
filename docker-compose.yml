version: '2'

services:

  langchain-server:
#    image: ds-api-server-kyc:latest
    image: llm-bot:latest
    command: python3 main2.py
    container_name: llm-bot
    ports:
      # - 7860:7860
      - 80:8080

    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - OPENAI_API_KEY=""
      - GOOGLE_APPLICATION_CREDENTIALS=/app/cohort.json

    logging:
      driver: "json-file"
      options:
          max-size: "1200m"
    # volumes:
    #   - /Users/akshatsrivastava/akshat_workspace/llm-test:/app
    
    # network_mode: "host"
    # networks:
    #   - host
  
  redis:
    container_name: redis
    image: redis:6-alpine
    expose:
      - '6379'
    ports:
      - 6379:6379 
    
    volumes:
      - /Users/akshatsrivastava/akshat_workspace/redis_bot:/app
    
    # network_mode: "host"
    # networks:
    #   - host

#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 - bp
#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